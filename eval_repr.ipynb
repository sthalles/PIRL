{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from models import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(X_train, y_train), (X, y) = cifar10.load_data()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CNN(X.shape[1:])\n",
    "_ = encoder(np.random.rand(1,32,32,3).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thallessilva/anaconda3/envs/tf2.0/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto').fit(np.reshape(X_train,(X_train.shape[0], -1)), y_train.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.4815 Test score: 0.388\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score:\", clf.score(np.reshape(X_train,(X_train.shape[0], -1)), y_train),\n",
    "      \"Test score:\", clf.score(np.reshape(X_test,(X_test.shape[0], -1)), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 64)\n",
      "(2000, 64)\n"
     ]
    }
   ],
   "source": [
    "X_train_repr, _ = encoder(tf.cast(X_train, tf.float32) / 255, training=True)\n",
    "X_test_repr, _ = encoder(tf.cast(X_test, tf.float32) / 255, training=True)\n",
    "print(X_train_repr.shape)\n",
    "print(X_test_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thallessilva/anaconda3/envs/tf2.0/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='auto').fit(X_train_repr, y_train.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41 0.3765\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train_repr, y_train.squeeze()), clf.score(X_test_repr, y_test.squeeze()))\n",
    "# 0.333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([0.9877376 , 1.291688  , 0.94789505, 1.0242503 , 0.9259114 ,\n",
       "       1.3375256 , 0.6599454 , 1.0366911 , 0.918199  , 1.2183697 ,\n",
       "       0.7277174 , 0.98015773, 1.1094345 , 1.4269246 , 0.7431276 ,\n",
       "       0.93318164, 0.7825998 , 0.8070295 , 2.1381342 , 0.6814266 ,\n",
       "       0.15767087, 0.5336    , 1.6411939 , 1.6537368 , 0.33571443,\n",
       "       0.81801295, 0.5415913 , 0.77718776, 0.9537431 , 1.0449755 ,\n",
       "       1.1843491 , 1.1581521 , 1.7765427 , 0.7688685 , 0.5137994 ,\n",
       "       1.9452035 , 0.89624137, 1.1433065 , 0.9553189 , 1.3854    ,\n",
       "       0.91827494, 1.0162283 , 0.56204134, 1.0575916 , 0.88932496,\n",
       "       0.8844476 , 0.44248322, 0.7263912 , 0.781695  , 0.75292903,\n",
       "       0.64554334, 0.6033028 , 0.42532334, 1.20373   , 1.0509102 ,\n",
       "       1.029772  , 0.980548  , 0.25524646, 0.6795023 , 1.0191046 ,\n",
       "       1.0212545 , 0.7047734 , 1.2244837 , 0.1741183 ], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       "array([0.48438543, 1.107085  , 1.3198764 , 1.1276953 , 1.2153352 ,\n",
       "       0.76859105, 0.78863096, 0.25211436, 0.90524405, 0.6600803 ,\n",
       "       0.5210695 , 0.8627778 , 0.50941485, 1.0363326 , 0.9314529 ,\n",
       "       0.8295021 , 0.7586357 , 1.0317823 , 0.29104218, 0.47168124,\n",
       "       0.68653774, 1.0084099 , 1.0879703 , 1.5259866 , 0.84300244,\n",
       "       0.8733821 , 0.7990243 , 0.67872065, 0.8022594 , 1.0281502 ,\n",
       "       0.91603804, 0.7491348 , 0.9870279 , 1.1949191 , 0.83879876,\n",
       "       0.24403733, 0.77000475, 0.9594132 , 1.4442179 , 0.98421896,\n",
       "       0.9238106 , 0.72643924, 0.7564484 , 0.6951094 , 1.0213232 ,\n",
       "       0.9016768 , 1.7896891 , 0.6840965 , 1.1426873 , 0.5269377 ,\n",
       "       1.0643253 , 0.5901062 , 1.2055218 , 0.765487  , 1.0559077 ,\n",
       "       0.50405896, 0.59914476, 0.5105461 , 0.77519536, 0.83468765,\n",
       "       1.2816627 , 1.003029  , 1.4140126 , 0.7084505 ], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  -0.8535534\n"
     ]
    }
   ],
   "source": [
    "cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
    "loss = cosine_loss([[0.0001, 1], [1., 1]], [[0.0002, 1], [0., 1]])\n",
    "\n",
    "print('Loss: ', loss.numpy())  # Loss: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.convert_to_tensor([1,6,5], dtype=tf.int32)\n",
    "b = tf.convert_to_tensor([4,3,2], dtype=tf.int32)\n",
    "res = tf.sets.intersection(a[None,:],b[None,:])\n",
    "print(tf.size(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999994 0.99999994]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([28.171087, 30.802778], dtype=np.float32)\n",
    "b = np.array([2.2323670e-06, 2.1488113e-06], dtype=np.float32)\n",
    "\n",
    "print(a / (a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int64, numpy=array([[1, 1, 0, 1, 1]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-25be6b1567da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositive_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "positive_indices = [0,1]\n",
    "\n",
    "memory = np.array([1,2,3,5,6,7,8,9,10])\n",
    "p = tf.ones(memory.shape[0])\n",
    "p[positive_indices] = 0\n",
    "p = p / np.sum(p)\n",
    "\n",
    "\n",
    "elems = tf.convert_to_tensor([1,2,3,5,6,7,8,9,10])\n",
    "samples = tf.random.categorical(tf.math.log([[1, 0, 0.3, 0.6]]), 3) # note log-prob\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
